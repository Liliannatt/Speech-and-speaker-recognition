# speech-and-speaker-recognition

## lab 1

Extracted Mel Filterbank and MFCC features, evaluated correlations, applied Dynamic Time Warping, and performed clustering and Gaussian Mixture Models.

### Results

![picture1](./images/1.png)
![picture2](./images/2.png)
![picture3](./images/3.png)

## lab 2

Implemented HMMs for isolated word recognition, including forward-backward, Viterbi algorithms, and Baum-Welch for Gaussian emissions.

### Results

![picture6](./images/6.png)
![picture7](./images/7.png)
![picture8](./images/8.png)

## lab 3

Developed phoneme recognition using HMMs and DNNs, trained models on TIDIGITS data, and evaluated frame-by-frame recognition using PyTorch.

### Results

![picture9](./images/9.png)
![picture10](./images/10.png)

## lab 4

Built an end-to-end speech recognizer using PyTorch, trained with CTC loss, and evaluated character/word error rates and N-gram models.
